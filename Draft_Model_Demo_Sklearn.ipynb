{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgji1QK5cNQJ"
      },
      "source": [
        "# Demo: Draft model + sklearn\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/basetenlabs/demos/blob/main/Draft_Model_Demo_Sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook presents a workflow with live reload: deploying your changes in seconds to a production-like environment for rapid iteration on your model serving code.\n",
        "\n",
        "All you'll need is a Baseten account and your API key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUSHXcEVcQ4L"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade baseten sklearn truss palmerpenguins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvvfZwe3dMjD"
      },
      "outputs": [],
      "source": [
        "# First, we train our model. Thanks to https://github.com/mcnakhaee/palmerpenguins for the training code!\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import FeatureUnion, make_pipeline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "### To deal with missing values\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "### Penguins!!\n",
        "from palmerpenguins import load_penguins\n",
        "\n",
        "data, target = load_penguins(return_X_y = True)\n",
        "imp = IterativeImputer(max_iter=10, random_state=0)\n",
        "clf = make_pipeline(imp, DecisionTreeClassifier())\n",
        "clf = clf.fit(data, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv95PaJydYdr"
      },
      "outputs": [],
      "source": [
        "# Then, let's package the model as a Truss\n",
        "import truss\n",
        "\n",
        "truss.mk_truss(clf, \"penguin-classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z7SS0BsdkXI"
      },
      "outputs": [],
      "source": [
        "# Then, we deploy it as a draft model\n",
        "\n",
        "import baseten\n",
        "\n",
        "api_key = \"YOUR API KEY HERE\"\n",
        "baseten.login(api_key)\n",
        "\n",
        "packaged_model = truss.from_directory(\"penguin-classifier\")\n",
        "baseten.deploy(\n",
        "    packaged_model,\n",
        "    model_name=\"Penguin Predictor\",\n",
        "    is_draft=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfMp1J-6CPHF"
      },
      "outputs": [],
      "source": [
        "# Once the model is deployed (which will take a few minutes), we can invoke it\n",
        "\n",
        "deployed_model_id = \"VERSION ID\" # See draft model to find version ID\n",
        "model_input = {\"inputs\": [[40, 20, 200, 4000]]}\n",
        "\n",
        "deployed_model = baseten.deployed_model_version_id(deployed_model_id)\n",
        "deployed_model.predict(model_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfMKdt3OC5dT"
      },
      "source": [
        "## Updating model input\n",
        "\n",
        "Now that we have deployed and invoked the model, we might want to adjust the model serving code. For example, let's adjust the model input format.\n",
        "\n",
        "Right now, it takes an input dictionary with a list of lists. Let's say you're developing this model to work with an existing applications, whose requirements state the model input must be formatted as follows:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"bill_length\": 40,\n",
        "  \"bill_depth\": 20,\n",
        "  \"flipper_length\": 200,\n",
        "  \"body_mass\": 4000\n",
        "}\n",
        "```\n",
        "\n",
        "We'll open up `penguin-classifier/model/model.py` and implement the `preprocess()` function with the following:\n",
        "\n",
        "```python\n",
        "def preprocess(self, request: Dict) -> Dict:\n",
        "    request = {\"inputs\": [[\n",
        "      request[\"bill_length\"],\n",
        "      request[\"bill_depth\"],\n",
        "      request[\"flipper_length\"],\n",
        "      request[\"body_mass\"]\n",
        "    ]]}\n",
        "    return request\n",
        "```\n",
        "\n",
        "After saving our changes, we'll reload the Truss and update the draft model. We'll call the newly deployed model right away as the model code will be reloaded live."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2vYWnU9EN7A"
      },
      "outputs": [],
      "source": [
        "# This time, deploying the updated model should take just seconds\n",
        "\n",
        "packaged_model = truss.from_directory(\"penguin-classifier\")\n",
        "baseten.deploy(\n",
        "    packaged_model,\n",
        "    model_name=\"Penguin Predictor\",\n",
        "    is_draft=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GuskX9xFJ61"
      },
      "outputs": [],
      "source": [
        "# Invoke the model again with new input format that matches the requirements\n",
        "\n",
        "model_input = {\n",
        "  \"bill_length\": 40,\n",
        "  \"bill_depth\": 20,\n",
        "  \"flipper_length\": 200,\n",
        "  \"body_mass\": 4000\n",
        "}\n",
        "\n",
        "deployed_model = baseten.deployed_model_version_id(deployed_model_id)\n",
        "deployed_model.predict(model_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPTxiEhYFmlc"
      },
      "source": [
        "## Formatting model output\n",
        "\n",
        "Turns out, the frontend team wants to return the model output to the user directly, and asks you to format the prediction as a string. No problem! You can test it out without waiting for your model to rebuild with live reload.\n",
        "\n",
        "We'll open up `penguin-classifier/model/model.py` again and fill in the `postprocess()` function with the following:\n",
        "\n",
        "```python\n",
        "def postprocess(self, request: Dict) -> Dict:\n",
        "    return f\"It appears as though you've discovered a {request['predictions'][0]} penguin!\"\n",
        "\n",
        "```\n",
        "\n",
        "After saving our changes, we'll once again reload the Truss and update the draft model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBLmTka1Gdlu"
      },
      "outputs": [],
      "source": [
        "# Again, deploying the updated model should take just seconds\n",
        "\n",
        "packaged_model = truss.from_directory(\"penguin-classifier\")\n",
        "baseten.deploy(\n",
        "    packaged_model,\n",
        "    model_name=\"Penguin Predictor\",\n",
        "    is_draft=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCyHcHoEGkfl"
      },
      "outputs": [],
      "source": [
        "# Invoke the model again with to get a user-friendly string\n",
        "\n",
        "model_input = {\n",
        "  \"bill_length\": 40,\n",
        "  \"bill_depth\": 20,\n",
        "  \"flipper_length\": 200,\n",
        "  \"body_mass\": 4000\n",
        "}\n",
        "\n",
        "deployed_model = baseten.deployed_model_version_id(deployed_model_id)\n",
        "deployed_model.predict(model_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQo1MkHoG0J2"
      },
      "source": [
        "## Deploying the final model\n",
        "\n",
        "Now that we are happy with our model, we can deploy it and it will no longer be a draft. Simply remove `is_draft=True` from the deployment script. Deploying the model for real doesn't use live reload, so take a break after all of your hard work and come back in a few minutes to invoke the model version with a new version ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnLYBkVBG1mx"
      },
      "outputs": [],
      "source": [
        "baseten.deploy(\n",
        "    packaged_model,\n",
        "    model_name=\"Penguin Predictor\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKs_UxbFHesD"
      },
      "outputs": [],
      "source": [
        "# Invoke the fully deployed model\n",
        "\n",
        "deployed_model_id = \"NEW VERSION ID\" # See model version to find version ID\n",
        "model_input = {\n",
        "  \"bill_length\": 40,\n",
        "  \"bill_depth\": 20,\n",
        "  \"flipper_length\": 200,\n",
        "  \"body_mass\": 4000\n",
        "}\n",
        "\n",
        "deployed_model = baseten.deployed_model_version_id(deployed_model_id)\n",
        "deployed_model.predict(model_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP_S6cqxG9F7"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 64-bit ('3.9.11')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "1fe11a838172db6ded9e0eaff73fa4c1868b66c7832ee9f6d2dd311612d2d593"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
